# 人間検出システムの計算方法（抽象的説明）

## 概要

現在の実装における画像計算処理を、抽象的な計算パターンとして説明します。

---

## 1. 計算パイプライン全体

```
入力: 深度画像 D(x,y) ∈ [0, MAX_DEPTH]
  ↓
[空間的ダウンサンプリング] (Coarse-to-Fine)
  ↓
[深度フィルタリング] (閾値ベース)
  ↓
[形態学的処理] (ノイズ除去)
  ↓
[連結成分解析] (領域検出)
  ↓
[特徴抽出] (重心、面積、形状)
  ↓
[幾何学的推定] (頭-足関係、身長推定)
  ↓
[座標変換] (画像座標 → toio座標)
  ↓
[トラッキング] (時系列整合性)
  ↓
出力: 人間の位置リスト {position, velocity, state}
```

---

## 2. 各計算ステップの詳細

### 2.1 空間的ダウンサンプリング (Spatial Downsampling)

**抽象的操作:**
```
D_coarse(x', y') = DOWNSAMPLE(D(x, y), scale_factor)
```
- **目的**: 計算量削減
- **方法**: 画像を1/Nに縮小（N=4）
- **効果**: ピクセル数が1/N²に減少 → 計算量が1/N²に削減

**実装:**
- `cv::resize(..., INTER_AREA)` - 面積平均による縮小
- `cv::resize(..., INTER_NEAREST)` - 最近傍補間（深度画像用）

---

### 2.2 深度フィルタリング (Threshold-based Filtering)

**抽象的操作:**
```
M(x, y) = 1 if d_min ≤ D(x, y) ≤ d_max else 0
```
- **目的**: 特定の深度範囲の点を抽出
- **パラメータ**: 
  - `d_min`, `d_max`: 深度範囲（例: 2300-2800mm）
- **出力**: バイナリマスク M(x, y)

**実装:**
- `cv::inRange()` - 範囲内の値を1、それ以外を0に

**使用例:**
- 頭検出: 2400-2600mm
- 足検出: 2300-2450mm

---

### 2.3 形態学的処理 (Morphological Operations)

**抽象的操作:**
```
M_cleaned = MORPH_CLOSE(MORPH_OPEN(M, kernel), kernel)
```
- **目的**: ノイズ除去、小さな穴の埋め合わせ
- **操作**:
  - `MORPH_CLOSE`: 膨張→収縮（小さな穴を埋める）
  - `MORPH_OPEN`: 収縮→膨張（小さなノイズを除去）
- **カーネル**: 楕円形カーネル（サイズ5×5）

**実装:**
- `cv::morphologyEx(..., MORPH_CLOSE)`
- `cv::morphologyEx(..., MORPH_OPEN)`

---

### 2.4 連結成分解析 (Connected Component Analysis)

**抽象的操作:**
```
{CC_i} = CONNECTED_COMPONENTS(M)
```
- **目的**: 連結した領域を検出
- **出力**: 連結成分の集合 {CC₁, CC₂, ..., CCₙ}
- **各成分**: 点の集合 CC_i = {p₁, p₂, ..., pₘ}

**実装:**
- `cv::findContours()` - 輪郭検出
- 外部輪郭のみ抽出 (`RETR_EXTERNAL`)

---

### 2.5 特徴抽出 (Feature Extraction)

#### 2.5.1 面積計算
```
Area(CC) = |CC|  // ピクセル数
```

#### 2.5.2 重心計算（モーメント）
```
centroid = (Σx, Σy) / |CC|
```
- **1次モーメント**: M₁₀ = Σx, M₀₁ = Σy
- **0次モーメント**: M₀₀ = |CC|
- **重心**: (M₁₀/M₀₀, M₀₁/M₀₀)

**実装:**
- `cv::moments()` - モーメント計算
- `cv::contourArea()` - 面積計算

---

### 2.6 距離ベースフィルタリング (Distance-based Filtering)

**抽象的操作:**
```
M_filtered = M ∩ {p: ||p - p_head|| ≤ r}
```
- **目的**: 頭中心からの距離でフィルタ
- **パラメータ**: 
  - `p_head`: 頭の位置
  - `r`: 検索半径（150mm = 15cm）
- **方法**: 円形マスクを作成してAND演算

**実装:**
- `cv::circle()` - 円形マスク作成
- `cv::bitwise_and()` - マスク適用

---

### 2.7 幾何学的推定 (Geometric Estimation)

#### 2.7.1 身長推定
```
height = ||p_head - p_foot|| × scale_factor
```
- **scale_factor**: ピクセル→mm変換係数（簡易版: 2.0）
- **検証**: min_height ≤ height ≤ max_height

#### 2.7.2 楕円領域推定
```
ellipse = ELLIPSE_FIT(p_head, p_foot, height)
```
- **中心**: (p_head + p_foot) / 2
- **サイズ**: width = height × aspect_ratio, height = height
- **角度**: atan2(foot.y - head.y, foot.x - head.x) + 90°

**実装:**
- `EstimateEllipse()` - 頭と足の位置から楕円を計算

---

### 2.8 フォールバック処理 (Fallback Mechanisms)

#### 2.8.1 トラッキングベース推定
```
if (検出失敗 && トラッキング情報あり) {
  if (静止中) {
    position = last_position;  // 前回の位置を使用
    confidence = 0.6;
  } else {
    position = ESTIMATE_FROM_HEAD(head, last_height);
    confidence = 0.45;
  }
}
```

#### 2.8.2 幾何学的推定
```
if (足が見つからない) {
  foot_position = head_position + (0, average_height / scale);
  confidence = 0.45;
}
```

---

### 2.9 座標変換 (Coordinate Transformation)

**抽象的操作:**
```
p_toio = H × p_image
```
- **H**: ホモグラフィ行列（3×3）
- **p_image**: 画像座標（同次座標）
- **p_toio**: toio座標

**実装:**
- `TransformImagePixelToToio()` - ホモグラフィ変換

---

### 2.10 トラッキング (Tracking)

#### 2.10.1 ID割り当て（最近傍マッチング）
```
id = argmin_i ||p_current - p_last[i]||
if (||p_current - p_last[id]|| > threshold) {
  id = NEW_ID();
}
```

#### 2.10.2 速度計算
```
velocity = (p_t - p_{t-1}) / Δt
```
- **平均速度**: 過去Nフレームの平均
- **単位**: mm/s

#### 2.10.3 動き状態判定
```
if (||p_t - p_{t-N}|| < threshold_distance && 
    ||velocity|| < threshold_velocity) {
  state = STANDING;
} else {
  state = MOVING;
}
```

---

## 3. 計算の複雑度

### 3.1 時間計算量

| 処理 | 計算量 | 説明 |
|------|--------|------|
| ダウンサンプリング | O(W×H) | 全ピクセル処理 |
| 深度フィルタリング | O(W×H) | 全ピクセル処理 |
| 形態学的処理 | O(W×H×K²) | K: カーネルサイズ |
| 連結成分解析 | O(W×H) | 全ピクセル走査 |
| モーメント計算 | O(N) | N: 輪郭点数 |
| 座標変換 | O(1) | 定数時間 |
| トラッキング | O(M) | M: トラッキング数 |

**合計**: O(W×H) （支配項は画像サイズ）

### 3.2 空間計算量

- **作業バッファ**: O(W×H) （マスク、フィルタ結果）
- **トラッキング状態**: O(M×N) （M: 人数、N: 履歴フレーム数）

---

## 4. 計算の最適化ポイント

### 4.1 Coarse-to-Fine
- **粗検出**: 低解像度で候補領域を絞り込み
- **精密検出**: ROI内のみ高解像度処理
- **効果**: 計算量を約1/16に削減（4倍縮小時）

### 4.2 バッファ再利用
- マスク、フィルタ結果をメンバ変数で保持
- メモリ割り当てを削減

### 4.3 フレームスキップ
- 全フレーム処理せず、Nフレームに1回処理
- 計算負荷を1/(N+1)に削減

---

## 5. 計算の信頼性

### 5.1 信頼度の計算

```
confidence = base_confidence × detection_quality × tracking_quality
```

- **base_confidence**: 基本信頼度（検出方法による）
- **detection_quality**: 検出品質（距離、面積など）
- **tracking_quality**: トラッキング品質（連続性、速度など）

### 5.2 フォールバック優先順位

1. **直接検出** (confidence = 0.8-0.9)
   - 頭と足の両方が検出された場合

2. **トラッキング補完** (confidence = 0.6-0.65)
   - 静止中で前回の位置を使用

3. **幾何学的推定** (confidence = 0.45-0.5)
   - 頭から平均身長で推定

---

## 6. 計算の改善案

### 6.1 深度→3D座標変換の精度向上

現在の実装では簡易的な変換を使用：
```
pixel → mm: scale_factor = 2.0 (固定)
```

改善案：
```
z_mm = depth_value × depth_scale
x_mm = (x_pixel - cx) / fx × z_mm
y_mm = (y_pixel - cy) / fy × z_mm
```
- カメラ内部パラメータ（fx, fy, cx, cy）を使用
- より正確な3D位置計算

### 6.2 頭中心からの検索半径の動的調整

現在: 固定半径（150mm）

改善案:
```
search_radius = f(last_height, motion_state, confidence)
```
- 身長に応じて半径を調整
- 移動中は半径を拡大

### 6.3 複数フレームの統合

現在: 単一フレーム処理

改善案:
```
position_t = α × detection_t + (1-α) × position_{t-1}
```
- 時間的な平滑化
- 検出の安定性向上

---

## 7. 計算パターンのまとめ

| パターン | 用途 | 実装 |
|---------|------|------|
| **空間的ダウンサンプリング** | 計算量削減 | `cv::resize()` |
| **閾値フィルタリング** | 深度範囲抽出 | `cv::inRange()` |
| **形態学的処理** | ノイズ除去 | `cv::morphologyEx()` |
| **連結成分解析** | 領域検出 | `cv::findContours()` |
| **モーメント計算** | 重心・面積計算 | `cv::moments()` |
| **距離フィルタリング** | 空間的制約 | 円形マスク + AND |
| **幾何学的推定** | 位置推定 | 頭-足関係から計算 |
| **ホモグラフィ変換** | 座標変換 | 行列乗算 |
| **最近傍マッチング** | トラッキング | 距離計算 + 最小値検索 |
| **時系列平滑化** | 安定化 | 移動平均、指数平滑化 |

---

## 8. 課題と改善の方向性

### 8.1 現在の課題

1. **深度→mm変換が簡易的**
   - 固定の変換係数を使用
   - カメラ内部パラメータを活用すべき

2. **検索半径が固定**
   - 身長に応じて動的に調整すべき

3. **単一フレーム処理**
   - 時間的な統合がない
   - フレーム間の平滑化が必要

### 8.2 改善の方向性

1. **3D座標変換の正確化**
   - カメラ内部パラメータを使用
   - 深度スケールを正確に取得

2. **適応的パラメータ調整**
   - 身長に応じた検索半径
   - 動き状態に応じたフィルタ調整

3. **時系列統合**
   - カルマンフィルタなどの状態推定
   - 複数フレームの統合

4. **マルチスケール処理**
   - 複数の検索半径で検出
   - 最適な結果を選択

---

## 9. 計算の抽象化レベル

### Level 1: ピクセルレベル
- 深度値の読み取り
- 閾値チェック

### Level 2: 領域レベル
- 連結成分の検出
- 領域の特徴抽出

### Level 3: オブジェクトレベル
- 頭と足の対応付け
- 人間としての認識

### Level 4: 時系列レベル
- トラッキング
- 動き状態の判定

### Level 5: 座標系レベル
- 画像座標→toio座標変換
- 世界座標系への統合

---

この計算パイプラインは、**階層的な特徴抽出**と**段階的な絞り込み**により、効率的に人間を検出しています。

